---
title: "autodiff"
author: "finistere2022"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exploration de `{{torch}}` pour la différentiation automatique

## Installation 

Le package [`torch`]() permet de faire de la différentiation automatique à condition de réécrire son code avec les fonctions de `torch`. Il est basé sur la libraire C++ `libtorch` fourni dans PyTorch. Contrairement à d'anciennes versions, torch ne **fait pas** appel à python et ne nécessite pas reticulate. L'installation en est d'autant plus simple: 

```{r, eval = FALSE}
install.packages(torch)
```

Lors de la première utilisation, `torch` vous demandera de télécharger des fichiers supplémentaires via: 

```{r}
torch::install_torch() ## si vous avez un GPU compatible avec CUDA
## torch::install_torch(type = "cpu") ## sinon
```

`torch` est surtout utilisé pour des applications en ML/IA mais on peut aussi l'utiliser pour des calculs de gradients, hessiennes et de l'optimisation dans des modèles plus simples. On va l'illustrer ici pour de la régression logistique. 

## Régression logistique avec `torch`

On va adopter un simple modèle de régression logistique:

$$
Y_i \sim \mathcal{B}(\sigma(\theta^T x_i)) \quad \text{avec} \quad \sigma(x) = \frac{1}{1 + e^{-x}}
$$

Le but est d'estimer $\theta$ et éventuellement les erreurs associées. On commence par générer des données. 

```{r}
set.seed(42)
n <- 100
p <- 5
X <- matrix(rnorm(n = n*p), ncol = p, nrow = n)
beta <- seq(-2, 2, length.out = p)
probs <- (X %*% beta) %>% as.vector()
Y <- rbernoulli(n = n, p = probs) + 0L
```

`torch` fonctionne avec ses propres types numériques, qu'il faut créer avec la fonction `torch_tensor()`.

```{r}
x <- torch_tensor(x)
```




# Exemple Tristan


# Section Felix

## Fonctions de torch compatibles avec autograd

- `torch_ones(NB_OF_ROWS, NB_OF_COLS, requires_grad = TRUE)` ou `torch_ones(VECTOR_OF_DIMS, requires_grad = TRUE)` : crée un tenseur rempli de 1.
- `torch_tensor(OBJECT, requires_grad = TRUE)` : convertit un objet R (vecteur, matrice ou array) en un tenseur torch.
- `$mean()`, `$sum()`, `$pow(ORDER)`, `$mm(MATRIX)` (matrix multiplication), cf les fonctions torch_* de la documentation R de torch.
- Les fonctions de torch peuvent s'utiliser de manière analogue aux pipes. Par exemple, `x$mm(w1)$add(b1)$clamp(min = 0)$mm(w2)$add(b2)`.

- `output$backward()` : effectue la propagation backward pour calculer les gradients successifs.
- `input$grad` : récupère le gradient de `output` par rapport à `input`.
- `midput$retain_grad()` : à lancer avant `$backward()$ et permet de stocker les gradients intermédiaires.

## Comment implémenter une fonction compatible avec autograd

Une fonction compatible avec autograd doit être définie via `autograd_function`, et posséder deux méthodes, `forward` et `backward`, qui déterminent respectivement quelle opération est exécutée par le code et comment calculer le gradient.

- `ctx` correspond aux objets partagés entre la méthode `forward` et la méthode `backward`.
- `$save_for_backward()` permet de sauvegarder des valeurs des inputs et/ou outputs à utiliser lors du calcul du gradient dans la méthode `backward`.

Exemple de code :

```{r}
log_base = autograd_function(
    
    forward = function(ctx, input, base) {
        ctx$save_for_backward(input = input, base = base)
        input$log() / log(base)
    },
    
    backward = function(ctx, grad_output) {
        vars = ctx$saved_variables
        list(input = grad_output / (vars$input * log(vars$base)))
    }
    
)

x <- torch_tensor(2, requires_grad = TRUE)
y <- log_base(x, exp(1))
y$backward()
x$grad
```

`backward` doit être capable de propager le calcul du gradient aux inputs de la fonction implémentée.
Par exemple, en considérant que la fonction implémentée correspond à la fonction $f$ dans le chainage 
$$x \xrightarrow[]{f} y \rightarrow z,$$
la méthode `backward` doit sortir $\partial z / \partial x = (\partial y / \partial x)(\partial z / \partial y)$, où dans l'exemple précédent $\partial z / \partial y$ est représenté par l'argument `grad_output`.

