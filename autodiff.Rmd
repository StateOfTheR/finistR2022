---
title: "autodiff"
author: "finistere2022"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exploration de `{{torch}}` pour la différentiation automatique

## Installation 

Le package [`torch`]() permet de faire de la différentiation automatique à condition de réécrire son code avec les fonctions de `torch`. Il est basé sur la libraire C++ `libtorch` fourni dans PyTorch. Contrairement à d'anciennes versions, torch ne **fait pas** appel à python et ne nécessite pas reticulate. L'installation en est d'autant plus simple: 

```{r, eval = FALSE}
install.packages(torch)
```

Lors de la première utilisation, `torch` vous demandera de télécharger des fichiers supplémentaires via: 

```{r}
torch::install_torch() ## si vous avez un GPU compatible avec CUDA
## torch::install_torch(type = "cpu") ## sinon
```

`torch` est surtout utilisé pour des applications en ML/IA mais on peut aussi l'utiliser pour des calculs de gradients, hessiennes et de l'optimisation dans des modèles plus simples. On va l'illustrer ici pour de la régression logistique. 

## Régression logistique avec `torch`

On va adopter un simple modèle de régression logistique:

$$
Y_i \sim \mathcal{B}(\sigma(\theta^T x_i)) \quad \text{avec} \quad \sigma(x) = \frac{1}{1 + e^{-x}}
$$

Le but est d'estimer $\theta$ et éventuellement les erreurs associées. On commence par générer des données. 

```{r}
set.seed(42)
n <- 100
p <- 5
X <- matrix(rnorm(n = n*p), ncol = p, nrow = n)
beta <- seq(-2, 2, length.out = p)
probs <- (X %*% beta) %>% as.vector()
Y <- rbernoulli(n = n, p = probs) + 0L
```

`torch` fonctionne avec ses propres types numériques, qu'il faut créer avec la fonction `torch_tensor()`.

```{r}
x <- torch_tensor(x)
```




## Exemple régression multivariée


Cet exemple a été réalisé à partir du blog [torch for optimization](https://blogs.rstudio.com/ai/posts/2021-04-22-torch-for-optimization/)


```{r}
rm(list=ls())
library(tidyverse)
library(torch)


## Generate the data
X <- cbind(rep(1,100),matrix(rnorm(1000),100,10))
Beta.true <- rnorm(11)
Y <- X%*%Beta.true + rnorm(100)
n <- nrow(X)

## Declare the loss function
Theta <- torch_tensor(rep(1,12) %>% as.matrix, requires_grad = TRUE)
X.tensor <- torch_tensor(X)
LogLik <- function(theta){
  n*torch_log(theta[12]) + torch_square(torch_norm(Y-torch_matmul(X.tensor,theta[1:11])))/(2*torch_square(theta[12]))
}
LogLik(Theta)

## Check with an R equivalent
LogLik.r <- function(theta){
  n*log(theta[12]) + sum((Y-X%*%theta[1:11])**2)/(2*theta[12])
}
LogLik.r(as.matrix(rep(1,12)))


## Specify the optimization parameters
num_iterations <- 1000
lr <- 0.01
optimizer <- optim_adam(Theta,lr)

## Optimization step description
calc_loss <- function() {
  
  optimizer$zero_grad()
  value <- LogLik(Theta)
  cat("Value is: ", as.numeric(value), "\n")

  value$backward()
  value
}

## Run the optimization
for (i in 1:num_iterations) {
  optimizer$step(calc_loss)
}

## Compare the coef estimates with the ones of lm 
Res <- lm(Y ~ X[,-1] )
Res$coefficients

plot(Res$coefficients,as.numeric(Theta)[-12])
abline(a=0,b=1,col=2)

## Compare the variances
summary(Res)$sigma**2
Theta[12]
```


 

